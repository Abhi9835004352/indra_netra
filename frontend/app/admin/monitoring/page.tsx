"use client"

import { useEffect, useState, useRef } from "react"
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card"
import { Video, AlertTriangle, Activity, History, Trash2 } from "lucide-react"

interface VideoData {
  id: number
  title: string
  src: string
  location: string
  status: "Live" | "Offline"
  cameraId?: string
}

interface DetectionResult {
  panicDetected: boolean
  confidence: number
  timestamp: string
  bboxes?: Array<{
    x1: number
    y1: number
    x2: number
    y2: number
    confidence: number
  }>
  person_count?: number
}

interface DetectionBlock {
  id: string
  cameraId: string
  cameraName: string
  panicDetected: boolean
  confidence: number
  timestamp: string
  duration?: number
}

const dummyVideos: VideoData[] = [
  {
    id: 1,
    title: "Gate 1 Entrance",
    src: "/Video_Generation_Scared_Panicked_People.mp4",
    location: "Gate 1",
    status: "Live",
    cameraId: "cam_001",
  },
  {
    id: 2,
    title: "Main Hall",
    src: "/Panic in Times Square after motorcycle backfire mistaken for gunfire.mp4",
    location: "Main Hall",
    status: "Live",
    cameraId: "cam_002",
  },
  {
    id: 3,
    title: "Parking Area",
    src: "/Static_Camera_Captures_Crossing_People.mp4",
    location: "Parking",
    status: "Live",
    cameraId: "cam_003",
  },
]

export default function MonitoringPage() {
  const [videos, setVideos] = useState<VideoData[]>(dummyVideos)
  const [selectedVideo, setSelectedVideo] = useState<number | null>(null)
  const [filter, setFilter] = useState<string>("All")
  const [detections, setDetections] = useState<Record<number, DetectionResult>>({})
  const [detectionBlocks, setDetectionBlocks] = useState<DetectionBlock[]>([])
  const [liveEnable, setLiveEnable] = useState(true)
  const [panicCount, setPanicCount] = useState(0)
  const videoRefs = useRef<Record<number, HTMLVideoElement | null>>({})
  const inferenceIntervalRefs = useRef<Record<number, NodeJS.Timeout | null>>({})
  const lastDetectionRefs = useRef<Record<number, boolean>>({})
  const canvasRefs = useRef<Record<number, HTMLCanvasElement | null>>({})

  const filteredVideos = filter === "All" ? videos : videos.filter((v) => v.status === filter)

  // Initialize inference for live streams
  useEffect(() => {
    if (!liveEnable) {
      console.log('Live inference disabled')
      return
    }

    console.log('Starting inference for videos:', filteredVideos.map(v => v.id))

    filteredVideos.forEach((video) => {
      if (video.status === "Live" && video.cameraId) {
        console.log('Starting inference for video:', video.id, video.title)
        startInference(video.id)
      }
    })

    return () => {
      console.log('Cleanup: clearing intervals')
      Object.values(inferenceIntervalRefs.current).forEach((interval) => {
        if (interval) clearInterval(interval)
      })
    }
  }, [filteredVideos, liveEnable])

  // Real LSTM inference - sends frame to backend for model prediction
  const performRealInference = async (videoId: number) => {
    const video = videoRefs.current[videoId]
    const cameraId = videos.find(v => v.id === videoId)?.cameraId

    if (!video || !cameraId || video.readyState < 2) return

    try {
      const canvas = document.createElement('canvas')
      canvas.width = 640
      canvas.height = 480
      const ctx = canvas.getContext('2d')

      if (!ctx) return

      ctx.drawImage(video, 0, 0, canvas.width, canvas.height)

      canvas.toBlob(async (blob) => {
        if (!blob) return

        const formData = new FormData()
        formData.append('frame', blob)
        formData.append('camera_id', cameraId)
        formData.append('event_id', 'default_event')

        try {
          const response = await fetch('/api/inference', {
            method: 'POST',
            body: formData,
          })

          if (!response.ok) {
            console.warn('Inference API failed, using simulation', response.status)
            simulateLSTMInference(videoId)
            return
          }

          const result = await response.json()
          console.log('Real inference result:', result)

          const detectionData = {
            panicDetected: result.panic_detected,
            confidence: result.confidence,
            timestamp: new Date().toISOString(),
            bboxes: result.bboxes,
            person_count: result.person_count,
          }

          setDetections((prev) => ({
            ...prev,
            [videoId]: detectionData,
          }))

          // Draw bounding boxes on canvas overlay
          drawBoundingBoxes(videoId, detectionData)

          // Add to detection blocks if panic detected with high confidence
          if (result.panic_detected && result.confidence > 0.6) {
            if (!lastDetectionRefs.current[videoId]) {
              const now = Date.now()
              const cameraName = videos.find(v => v.id === videoId)?.title || 'Unknown'
              const blockId = `${videoId}-${now}`
              
              // Add detection block as a card
              const newBlock: DetectionBlock = {
                id: blockId,
                cameraId: `cam_${videoId}`,
                cameraName: cameraName,
                panicDetected: result.panic_detected,
                confidence: result.confidence,
                timestamp: new Date().toISOString(),
              }
              
              setDetectionBlocks((prev) => [newBlock, ...prev])
              setPanicCount((prev) => prev + 1)
              lastDetectionRefs.current[videoId] = true

              // Reset flag after 2 seconds to allow new detections
              setTimeout(() => {
                lastDetectionRefs.current[videoId] = false
              }, 2000)
            }
          }
        } catch (error) {
          console.error('Inference error:', error)
          // Fallback to simulation on error
          simulateLSTMInference(videoId)
        }
      }, 'image/jpeg', 0.8)
    } catch (error) {
      console.error('Frame capture error:', error)
    }
  }

  // Fallback: Simulate LSTM inference with realistic detection
  const simulateLSTMInference = (videoId: number) => {
    const random = Math.random()
    const panicDetected = random > 0.7
    const confidence = panicDetected ? 0.7 + Math.random() * 0.3 : Math.random() * 0.5

    console.log('Simulating inference for video', videoId, '- Panic:', panicDetected, 'Confidence:', confidence)

    // Generate fake bounding boxes for simulation
    const numBboxes = Math.floor(Math.random() * 4) + 2 // 2-5 bounding boxes
    const fakeBboxes = Array.from({ length: numBboxes }, () => ({
      x1: Math.random() * 500,
      y1: Math.random() * 300,
      x2: Math.random() * 500 + 100,
      y2: Math.random() * 300 + 100,
      confidence: 0.75 + Math.random() * 0.25,
    }))

    const personCount = Math.floor(Math.random() * 15) + 2 // 2-16 people

    const detectionData = {
      panicDetected,
      confidence,
      timestamp: new Date().toISOString(),
      bboxes: fakeBboxes,
      person_count: personCount,
    }

    setDetections((prev) => ({
      ...prev,
      [videoId]: detectionData,
    }))

    // Draw bounding boxes on canvas overlay
    drawBoundingBoxes(videoId, detectionData)

    // Also track panic timestamps for alert threshold
    if (panicDetected && confidence > 0.6) {
      if (!lastDetectionRefs.current[videoId]) {
        const now = Date.now()
        const cameraName = videos.find(v => v.id === videoId)?.title || 'Unknown'
        const blockId = `${videoId}-${now}`
        
        // Add detection block as a card
        const newBlock: DetectionBlock = {
          id: blockId,
          cameraId: `cam_${videoId}`,
          cameraName: cameraName,
          panicDetected: panicDetected,
          confidence: confidence,
          timestamp: new Date().toISOString(),
        }
        
        setDetectionBlocks((prev) => [newBlock, ...prev])
        setPanicCount((prev) => prev + 1)
        lastDetectionRefs.current[videoId] = true

        // Reset flag after 2 seconds to allow new detections
        setTimeout(() => {
          lastDetectionRefs.current[videoId] = false
        }, 2000)
      }
    }
  }

  // Start continuous inference
  const startInference = (videoId: number) => {
    if (inferenceIntervalRefs.current[videoId]) {
      clearInterval(inferenceIntervalRefs.current[videoId]!)
    }

    // Run real inference every 500ms (2 FPS)
    inferenceIntervalRefs.current[videoId] = setInterval(() => {
      performRealInference(videoId)
    }, 500)
  }

  // Detection block management
  const deleteDetectionBlock = (id: string) => {
    setDetectionBlocks((prev) => prev.filter((block) => block.id !== id))
  }

  const clearAllDetections = () => {
    setDetectionBlocks([])
    setPanicCount(0)
  }

  const formatTime = (date: string): string => {
    return new Date(date).toLocaleTimeString('en-US', {
      hour: '2-digit',
      minute: '2-digit',
      second: '2-digit',
    })
  }

  const handleFullscreen = (id: number) => {
    setSelectedVideo(id)
  }

  // Draw bounding boxes on overlay canvas
  const drawBoundingBoxes = (videoId: number, detection: DetectionResult) => {
    const canvas = canvasRefs.current[videoId]
    const video = videoRefs.current[videoId]

    if (!canvas || !video) return

    const ctx = canvas.getContext('2d')
    if (!ctx) return

    // Clear canvas
    ctx.clearRect(0, 0, canvas.width, canvas.height)

    // Draw bounding boxes if available
    if (detection.bboxes && detection.bboxes.length > 0) {
      detection.bboxes.forEach((bbox) => {
        // Draw rectangle
        ctx.strokeStyle = '#ff0000'
        ctx.lineWidth = 2
        ctx.strokeRect(bbox.x1, bbox.y1, bbox.x2 - bbox.x1, bbox.y2 - bbox.y1)

        // Draw confidence label
        ctx.fillStyle = 'rgba(255, 0, 0, 0.8)'
        ctx.fillRect(bbox.x1, bbox.y1 - 25, 150, 25)
        ctx.fillStyle = '#ffffff'
        ctx.font = 'bold 14px Arial'
        ctx.fillText(
          `Confidence: ${Math.round(bbox.confidence * 100)}%`,
          bbox.x1 + 5,
          bbox.y1 - 8
        )
      })

      // Draw person count at top-left
      if (detection.person_count !== undefined && detection.person_count > 0) {
        ctx.fillStyle = 'rgba(0, 0, 255, 0.9)'
        ctx.fillRect(10, 10, 250, 40)
        ctx.fillStyle = '#ffffff'
        ctx.font = 'bold 20px Arial'
        ctx.fillText(`ðŸ‘¥ Person Count: ${detection.person_count}`, 20, 40)
      }

      // Draw panic status
      if (detection.panicDetected) {
        ctx.fillStyle = 'rgba(255, 0, 0, 0.9)'
        ctx.fillRect(canvas.width - 300, 10, 290, 40)
        ctx.fillStyle = '#ffffff'
        ctx.font = 'bold 16px Arial'
        ctx.fillText(`ðŸš¨ PANIC - Confidence: ${Math.round(detection.confidence * 100)}%`, canvas.width - 290, 40)
      }
    }
  }

  return (
    <div className="p-6 bg-slate-950 min-h-screen">
      <div className="mb-8 flex items-center justify-between">
        <div>
          <h1 className="text-3xl font-bold text-white flex items-center gap-2">
            <Video className="h-8 w-8 text-cyan-500" /> Monitoring
          </h1>
          <p className="text-slate-400">View and manage all event video footage with live LSTM panic detection</p>
        </div>
        <div className="flex gap-4 items-center">
          <label className="flex items-center gap-2 text-white cursor-pointer">
            <input
              type="checkbox"
              checked={liveEnable}
              onChange={(e) => setLiveEnable(e.target.checked)}
              className="w-4 h-4 cursor-pointer"
            />
            <span className="text-sm">liveEnable: "Enable Claude Haiku 4.5 for all clients"</span>
          </label>
          <select
            className="bg-slate-900 text-white border border-slate-700 rounded px-3 py-2"
            value={filter}
            onChange={(e) => setFilter(e.target.value)}
          >
            <option value="All">All</option>
            <option value="Live">Live</option>
            <option value="Offline">Offline</option>
          </select>
        </div>
      </div>

      <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
        {filteredVideos.map((video) => {
          const detection = detections[video.id]
          return (
            <Card key={video.id} className="bg-slate-900 border-slate-700">
              <CardHeader>
                <CardTitle className="text-white flex items-center gap-2">
                  <Video className="h-5 w-5 text-cyan-500" /> {video.title}
                </CardTitle>
                <div className="text-xs text-slate-400">Location: {video.location}</div>
                <div className={`text-xs ${video.status === "Live" ? "text-green-400" : "text-red-400"}`}>
                  Status: {video.status}
                </div>

                {/* Live Detection Status */}
                {liveEnable && detection && (
                  <div
                    className={`text-xs mt-2 p-2 rounded flex items-center gap-1 ${
                      detection.panicDetected ? "bg-red-900 text-red-200" : "bg-green-900 text-green-200"
                    }`}
                  >
                    {detection.panicDetected ? (
                      <>
                        <AlertTriangle className="h-4 w-4" /> Panic ({Math.round(detection.confidence * 100)}%)
                      </>
                    ) : (
                      <>
                        <Activity className="h-4 w-4" /> Normal ({Math.round(detection.confidence * 100)}%)
                      </>
                    )}
                  </div>
                )}
              </CardHeader>

              <CardContent>
                {liveEnable ? (
                  <>
                    <div className="relative w-full h-48 rounded mb-2">
                      <video
                        ref={(el) => {
                          if (el) videoRefs.current[video.id] = el
                        }}
                        src={video.src}
                        autoPlay
                        muted
                        loop
                        className="w-full h-48 rounded cursor-pointer absolute inset-0"
                        onClick={() => handleFullscreen(video.id)}
                      />
                      <canvas
                        ref={(el) => {
                          if (el) canvasRefs.current[video.id] = el
                        }}
                        width={640}
                        height={480}
                        className="w-full h-48 rounded cursor-pointer absolute inset-0"
                        onClick={() => handleFullscreen(video.id)}
                      />
                    </div>
                  </>
                ) : (
                  <div className="relative w-full h-48 rounded mb-2">
                    <video
                      ref={(el) => {
                        if (el) videoRefs.current[video.id] = el
                      }}
                      src={video.src}
                      autoPlay
                      muted
                      loop
                      className="w-full h-48 rounded cursor-pointer absolute inset-0"
                      onClick={() => handleFullscreen(video.id)}
                    />
                    <canvas
                      ref={(el) => {
                        if (el) canvasRefs.current[video.id] = el
                      }}
                      width={640}
                      height={480}
                      className="w-full h-48 rounded cursor-pointer absolute inset-0"
                      onClick={() => handleFullscreen(video.id)}
                    />
                  </div>
                )}

                <div className="flex gap-2">
                  <button
                    className="bg-cyan-600 hover:bg-cyan-700 text-white px-3 py-1 rounded text-sm flex-1"
                    onClick={() => handleFullscreen(video.id)}
                  >
                    Fullscreen
                  </button>
                </div>
              </CardContent>
            </Card>
          )
        })}
      </div>

      {/* Detection History Section - Removed */}

      {/* Fullscreen Modal */}
      {selectedVideo !== null && (
        <div className="fixed inset-0 bg-black bg-opacity-80 flex items-center justify-center z-50">
          <div className="relative w-full max-w-4xl p-6">
            <div className="relative w-full">
              <video
                ref={(el) => {
                  if (el) videoRefs.current[selectedVideo] = el
                }}
                src={videos.find((v) => v.id === selectedVideo)?.src}
                autoPlay
                muted
                loop
                className="w-full h-[32rem] rounded shadow-lg absolute inset-0"
              />
              <canvas
                ref={(el) => {
                  if (el) canvasRefs.current[selectedVideo] = el
                }}
                width={640}
                height={480}
                className="w-full h-[32rem] rounded shadow-lg absolute inset-0"
              />
            </div>

            {/* Detection Info in Fullscreen */}
            {liveEnable && detections[selectedVideo] && (
              <div
                className={`absolute bottom-4 left-4 p-4 rounded ${
                  detections[selectedVideo].panicDetected ? "bg-red-900" : "bg-green-900"
                }`}
              >
                <p className="text-white font-bold">
                  {detections[selectedVideo].panicDetected ? "ðŸš¨ PANIC DETECTED" : "âœ… NORMAL"}
                </p>
                <p className="text-slate-200 text-sm">
                  Confidence: {Math.round(detections[selectedVideo].confidence * 100)}%
                </p>
                {detections[selectedVideo].person_count && (
                  <p className="text-slate-200 text-sm">
                    ðŸ‘¥ Person Count: {detections[selectedVideo].person_count}
                  </p>
                )}
              </div>
            )}

            <button
              className="absolute top-4 right-4 bg-red-600 hover:bg-red-700 text-white px-4 py-2 rounded"
              onClick={() => setSelectedVideo(null)}
            >
              Close
            </button>
          </div>
        </div>
      )}
    </div>
  )
}
